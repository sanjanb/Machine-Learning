---
layout: default
title: "Project: Gradient Descent"
permalink: projects/gradient-descent.html
sidebar: sidebar
image: /Machine-Learning/assets/images/og/project-3-gradient-descent.svg
---

# Project: Gradient Descent (Applied)

This project demonstrates gradient descent and its variants (batch, stochastic, mini-batch) on practical problems.

## Summary

- Goal: Optimize parameters to minimize a cost function
- Concepts: Learning rate, convergence, cost surfaces, updates
- Experiments: Different learning rates, convergence plots

## Notebook

- [Rendered notebook](/Machine-Learning/projects/gradient-descent/notebook)
- Open in Colab: [Launch](/redirect?target=https%3A%2F%2Fcolab.research.google.com%2Fgithub%2Fsanjanb%2FMachine-Learning%2Fblob%2Fmain%2Fprojects%2F3.%2520Gradient%2520Descent%2Fgradient-descent-and-cost-function.ipynb)

## Dataset

- [test_scores.csv](/Machine-Learning/projects/3.%20Gradient%20Descent/test_scores.csv)

## Related Topics

- [Gradient Descent Theory](/Machine-Learning/topics/gradient_descent.html)
- [Cost Functions](/Machine-Learning/topics/cost_functions.html)
