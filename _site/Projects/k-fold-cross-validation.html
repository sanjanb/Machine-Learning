<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="My personal documentation for Machine Learning course"
    />

    <!-- SEO Meta Tags -->
    <meta
      property="og:title"
      content="Project: K-Fold Cross Validation"
    />
    <meta
      property="og:description"
      content="My personal documentation for Machine Learning course"
    />
    <meta property="og:type" content="website" />
    <meta property="og:url" content="http://localhost:4000/Machine-Learning/projects/k-fold-cross-validation.html" />
    <meta property="og:site_name" content="Machine Learning Notes" />

    <meta name="twitter:card" content="summary" />
    <meta
      name="twitter:title"
      content="Project: K-Fold Cross Validation"
    />
    <meta
      name="twitter:description"
      content="My personal documentation for Machine Learning course"
    />

    <!-- Favicon -->
    <link
      rel="icon"
      type="image/x-icon"
      href="/Machine-Learning/assets/favicon.ico"
    />

    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Project: K-Fold Cross Validation | Machine Learning Notes</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Project: K-Fold Cross Validation" />
<meta name="author" content="Your Name" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="My personal documentation for Machine Learning course" />
<meta property="og:description" content="My personal documentation for Machine Learning course" />
<link rel="canonical" href="http://localhost:4000/Machine-Learning/projects/k-fold-cross-validation.html" />
<meta property="og:url" content="http://localhost:4000/Machine-Learning/projects/k-fold-cross-validation.html" />
<meta property="og:site_name" content="Machine Learning Notes" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Project: K-Fold Cross Validation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Your Name"},"description":"My personal documentation for Machine Learning course","headline":"Project: K-Fold Cross Validation","url":"http://localhost:4000/Machine-Learning/projects/k-fold-cross-validation.html"}</script>
<!-- End Jekyll SEO tag -->


    <!-- Google Analytics - Replace with your tracking ID -->
    

    <title>Project: K-Fold Cross Validation</title>
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto,
          sans-serif;
        line-height: 1.6;
        margin: 0;
        padding: 20px;
      }
      .container {
        max-width: 1200px;
        margin: 0 auto;
        display: flex;
        gap: 20px;
      }
      .sidebar {
        flex: 0 0 250px;
        background: #f8f9fa;
        padding: 20px;
        border-radius: 8px;
      }
      .content {
        flex: 1;
        background: white;
        padding: 20px;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
      }
      .nav-link {
        display: block;
        padding: 8px 12px;
        text-decoration: none;
        color: #333;
        border-radius: 4px;
        margin: 2px 0;
      }
      .nav-link:hover {
        background: #e9ecef;
      }
      h1,
      h2,
      h3 {
        color: #2c3e50;
      }
      code {
        background: #f4f4f4;
        padding: 2px 6px;
        border-radius: 3px;
      }
      pre {
        background: #f8f9fa;
        padding: 15px;
        border-radius: 5px;
        overflow-x: auto;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <nav class="sidebar">
        <h3>Navigation</h3>
        <a href="/Machine-Learning/" class="nav-link">Home</a>
        <h4>Introduction</h4>
        <a href="/Machine-Learning/intro/syllabus.html" class="nav-link"
          >Syllabus</a
        >
        <h4>Lectures</h4>
        <a href="/Machine-Learning/lectures/lecture1.html" class="nav-link"
          >Lecture 1</a
        >
        <a href="/Machine-Learning/lectures/lecture2.html" class="nav-link"
          >Lecture 2</a
        >
        <h4>Topics</h4>
        <a
          href="/Machine-Learning/topics/linear_regression.html"
          class="nav-link"
          >Linear Regression</a
        >
        <a
          href="/Machine-Learning/topics/logistic_regression.html"
          class="nav-link"
          >Logistic Regression</a
        >
        <a
          href="/Machine-Learning/topics/gradient_descent.html"
          class="nav-link"
          >Gradient Descent</a
        >
        <a href="/Machine-Learning/topics/cost_functions.html" class="nav-link"
          >Cost Functions</a
        >
        <h4>Projects</h4>
        <a href="/Machine-Learning/projects/" class="nav-link">Projects</a>
        <h4>References</h4>
        <a href="/Machine-Learning/references/books.html" class="nav-link"
          >Books & Papers</a
        >
        <a href="/Machine-Learning/Foundations/" class="nav-link"
          >Foundations</a
        >
      </nav>
      <main class="content"><h1 id="project-12-k-fold-cross-validation">Project 12: K-Fold Cross Validation</h1>

<p>This project demonstrates K-Fold cross validation to assess model generalization and tune hyperparameters.</p>

<h2 id="summary">Summary</h2>

<ul>
  <li>Goal: Estimate model performance reliably across folds</li>
  <li>Concepts: Stratified K-Fold, shuffle, leakage prevention, scoring metrics</li>
  <li>Pipeline: Split → Train → Validate → Aggregate</li>
</ul>

<h2 id="notebook">Notebook</h2>

<ul>
  <li><a href="/Machine-Learning/projects/k-fold-cross-validation/notebook">Rendered notebook</a></li>
</ul>

<h2 id="exercise">Exercise</h2>

<p>Explore the exercises in the project folder if available.</p>

<h2 id="related-topics">Related Topics</h2>

<ul>
  <li><a href="/Machine-Learning/projects/train-test-split.html">Train/Test Split</a></li>
  <li><a href="/Machine-Learning/topics/cost_functions.html">Cost Functions</a></li>
</ul>

<h2 id="key-learnings">Key Learnings</h2>

<h2 id="1-the-model-evaluation-dilemma">1. The Model Evaluation Dilemma</h2>

<p>The video starts by framing the core problem: <strong>How do you reliably determine which machine learning model (e.g., SVM, Random Forest, Logistic Regression) is best for a given problem?</strong> [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=0">00:00</a>]</p>

<h3 id="a-problem-with-using-all-training-data">A. Problem with Using All Training Data</h3>

<p>If you train a model on <strong>100% of your data</strong> and then test it on the <strong>exact same 100% of data</strong>, the model’s score will be artificially high. This is like giving a student the test questions beforehand—the score doesn’t reflect their true knowledge or ability to generalize to new, unseen problems. [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=86">01:26</a>]</p>

<h3 id="b-limitations-of-simple-train-test-split-the-flaw">B. Limitations of Simple Train-Test Split (The Flaw)</h3>

<p>The <strong>train-test split</strong> method (e.g., 70% train, 30% test) improves on the first method because the test set is unseen. However, it still has a major flaw: the performance score is highly dependent on <strong>how the random split happened</strong> [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=180">03:00</a>].</p>

<ul>
  <li><strong>Scenario:</strong> If the 70% training data contains only easy samples (e.g., all algebra problems), and the 30% test data contains only difficult, unseen samples (e.g., all calculus problems), the model will perform poorly, and the score will be an <strong>unreliable underestimate</strong> of its true capability [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=187">03:07</a>].</li>
  <li><strong>Proof:</strong> The video demonstrates that running <code class="language-plaintext highlighter-rouge">train_test_split</code> multiple times causes the scores of the same model (e.g., Logistic Regression) to fluctuate significantly, proving that a single split is not sufficient for robust evaluation [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=425">07:05</a>].</li>
</ul>

<hr />

<h2 id="2-k-fold-cross-validation-the-solution">2. K-Fold Cross-Validation (The Solution)</h2>

<p><strong>K-Fold Cross-Validation</strong> addresses the limitations of a single train-test split by ensuring that <strong>every sample in the dataset is used for both training and testing</strong> exactly once.</p>

<h3 id="a-the-mechanism">A. The Mechanism</h3>

<ol>
  <li><strong>Divide into Folds:</strong> The entire dataset is divided into $K$ equally sized, non-overlapping subsets, called <strong>folds</strong> (the video typically uses $K=5$ or $K=10$) [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=216">03:36</a>].</li>
  <li><strong>Iterative Training:</strong> The model is trained and tested $K$ times (in $K$ iterations).</li>
  <li><strong>Iteration $i$:</strong> In the $i$-th iteration:
    <ul>
      <li><strong>Test Set:</strong> Fold $i$ is reserved as the <strong>testing set</strong>.</li>
      <li><strong>Training Set:</strong> The remaining $K-1$ folds are combined to form the <strong>training set</strong>.</li>
      <li>A performance score is recorded.</li>
    </ul>
  </li>
  <li><strong>Final Score:</strong> The $K$ individual scores are averaged together to produce the final, <strong>robust performance metric</strong> [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=254">04:14</a>].</li>
</ol>

<h3 id="b-stratified-k-fold">B. Stratified K-Fold</h3>

<p>The video introduces <strong>Stratified K-Fold</strong>, a superior version of the standard K-Fold [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=745">12:25</a>].</p>

<ul>
  <li><strong>Problem:</strong> If the target variable is imbalanced (e.g., 90% Class A, 10% Class B), a random split might result in some folds having very few or zero samples of Class B.</li>
  <li><strong>Solution:</strong> Stratified K-Fold ensures that the <strong>proportion of target classes is maintained</strong> (stratified) within each of the $K$ folds. This is especially important for classification problems to ensure fair testing [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=757">12:37</a>].</li>
</ul>

<hr />

<h2 id="3-practical-implementation-in-scikit-learn">3. Practical Implementation in Scikit-learn</h2>

<p>The video demonstrates two ways to implement cross-validation using scikit-learn.</p>

<h3 id="a-manual-k-fold-for-understanding">A. Manual K-Fold (for Understanding)</h3>

<p>The instructor first manually demonstrates the K-Fold process using the <code class="language-plaintext highlighter-rouge">KFold</code> or <code class="language-plaintext highlighter-rouge">StratifiedKFold</code> class [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=498">08:18</a>]. This involves:</p>

<ol>
  <li>Initializing <code class="language-plaintext highlighter-rouge">StratifiedKFold(n_splits=K)</code>.</li>
  <li>Looping through the folds using <code class="language-plaintext highlighter-rouge">skf.split(X, Y)</code>.</li>
  <li>Inside the loop, manually subsetting the data using the <code class="language-plaintext highlighter-rouge">train_index</code> and <code class="language-plaintext highlighter-rouge">test_index</code> [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=873">14:33</a>].</li>
  <li>Training the model (<code class="language-plaintext highlighter-rouge">.fit()</code>) and recording the score (<code class="language-plaintext highlighter-rouge">.score()</code>) for each iteration.</li>
  <li>Appending the scores to a list (e.g., <code class="language-plaintext highlighter-rouge">scores_lr.append(...)</code>) [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=1045">17:25</a>].</li>
</ol>

<p>This manual approach is crucial for understanding the algorithm’s mechanics but is rarely used in production.</p>

<h3 id="b-using-cross_val_score-the-real-world-method">B. Using <code class="language-plaintext highlighter-rouge">cross_val_score</code> (The Real-World Method)</h3>

<p>For production use, scikit-learn provides the one-line function <strong><code class="language-plaintext highlighter-rouge">cross_val_score</code></strong>, which automates the entire K-Fold process [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=1167">19:27</a>].</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="c1"># Performs 5-fold cross-validation by default (or set cv=K)
</span><span class="n">scores</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span>
    <span class="n">estimator</span><span class="o">=</span><span class="nc">LogisticRegression</span><span class="p">(),</span>
    <span class="n">X</span><span class="o">=</span><span class="n">digits</span><span class="p">.</span><span class="n">data</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">digits</span><span class="p">.</span><span class="n">target</span><span class="p">,</span>
    <span class="n">cv</span><span class="o">=</span><span class="mi">10</span>  <span class="c1"># Use 10 folds
</span><span class="p">)</span>

<span class="c1"># 'scores' is an array of the 10 individual scores.
</span></code></pre></div></div>

<p>This single line achieves the same result as the lengthy manual loop, providing a fast and robust way to get all $K$ scores.</p>

<hr />

<h2 id="4-key-use-cases-for-cross-validation">4. Key Use Cases for Cross-Validation</h2>

<p>Cross-validation is not just for measuring a model’s final performance; it is a critical tool in the development process.</p>

<h3 id="a-model-comparison-algorithm-selection">A. Model Comparison (Algorithm Selection)</h3>

<p>By running <code class="language-plaintext highlighter-rouge">cross_val_score</code> on multiple different algorithms (Logistic Regression, SVM, Random Forest), you can reliably compare their average performance on your dataset and select the best one [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=1268">21:08</a>]. The model with the highest average cross-validation score is the best choice for your problem.</p>

<h3 id="b-parameter-tuning-hyperparameter-optimization">B. Parameter Tuning (Hyperparameter Optimization)</h3>

<p>Cross-validation is essential for finding the optimal <strong>hyperparameters</strong> for a single model (e.g., the number of trees <code class="language-plaintext highlighter-rouge">n_estimators</code> in a Random Forest) [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=1318">21:58</a>].</p>

<ol>
  <li>Run <code class="language-plaintext highlighter-rouge">cross_val_score</code> with <code class="language-plaintext highlighter-rouge">n_estimators=5</code>. Record the average score.</li>
  <li>Run <code class="language-plaintext highlighter-rouge">cross_val_score</code> with <code class="language-plaintext highlighter-rouge">n_estimators=50</code>. Record the average score.</li>
</ol>

<p>By comparing the average scores, you can determine which parameter setting yields the most generalized and accurate model. This process demonstrates that machine learning model selection is not a fixed scientific equation but a <strong>trial-and-error process</strong> guided by rigorous testing [<a href="http://www.youtube.com/watch?v=gJo0uNL-5Qw&amp;t=1425">23:45</a>].</p>

<p>http://googleusercontent.com/youtube_content/19</p>

</main>
    </div>
  </body>
</html>
